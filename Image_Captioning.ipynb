{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMKhjmAzVJg10E0/BLeBCH+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karn2898/Visual-semantic-pipeline/blob/main/Image_Captioning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fdfm-veok-sC",
        "outputId": "724e07b4-d1b9-4329-ece8-d66a725711b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cpu)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision spacy pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd428dd2",
        "outputId": "c05f45c8-a28e-4bdb-e861-63b445ce402f"
      },
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def create_dummy_data():\n",
        "    # 1. Create images directory\n",
        "    if not os.path.exists('images'):\n",
        "        os.makedirs('images')\n",
        "        print(\"Created 'images' directory.\")\n",
        "\n",
        "    # 2. Generate 5 dummy noise images\n",
        "    dummy_image_names = []\n",
        "    print(\"Generating dummy images...\")\n",
        "    for i in range(5):\n",
        "        img_name = f'test_image_{i}.jpg'\n",
        "\n",
        "        arr = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)\n",
        "        img = Image.fromarray(arr)\n",
        "        img.save(os.path.join('images', img_name))\n",
        "        dummy_image_names.append(img_name)\n",
        "\n",
        "\n",
        "    print(\"Generating dummy captions file...\")\n",
        "    data = {\n",
        "        'image': dummy_image_names * 2,  # 2 captions per image\n",
        "        'caption': [\n",
        "            \"A dog running on green grass\",\n",
        "            \"A person riding a red bicycle\",\n",
        "            \"A white cat sitting on a sofa\",\n",
        "            \"A group of birds flying in the blue sky\",\n",
        "            \"A silver car parked on the street\",\n",
        "            \"The dog chases a yellow ball\",\n",
        "            \"The cyclist wears a safety helmet\",\n",
        "            \"The cat looks sleepy and comfortable\",\n",
        "            \"The birds are migrating south for winter\",\n",
        "            \"The car is shiny and new\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    df.to_csv('captions.txt', index=False)\n",
        "    print(\"Success! Created 'captions.txt' and 'images/' folder.\")\n",
        "    print(\"You can now run 'data_loader.py' to test the loader.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    create_dummy_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmrLq7HYoZEF",
        "outputId": "d209de23-8a82-4dde-9c73-e92f80192e7a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating dummy images...\n",
            "Generating dummy captions file...\n",
            "Success! Created 'captions.txt' and 'images/' folder.\n",
            "You can now run 'data_loader.py' to test the loader.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import spacy\n",
        "import torch\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from typing import List, Tuple, Any\n",
        "\n",
        "# Load Spacy English tokenizer\n",
        "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "class Vocabulary:\n",
        "    \"\"\"\n",
        "    Builds a vocabulary from text data to convert words to numerical indices.\n",
        "    \"\"\"\n",
        "    def __init__(self, freq_threshold: int):\n",
        "        self.itos = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
        "        self.stoi = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
        "        self.freq_threshold = freq_threshold\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.itos)\n",
        "\n",
        "    @staticmethod\n",
        "    def tokenizer_eng(text: str) -> List[str]:\n",
        "        return [tok.text.lower() for tok in spacy_eng.tokenizer(text)]\n",
        "\n",
        "    def build_vocabulary(self, sentence_list: List[str]):\n",
        "        frequencies = {}\n",
        "        idx = 4\n",
        "\n",
        "        for sentence in sentence_list:\n",
        "            for word in self.tokenizer_eng(sentence):\n",
        "                if word not in frequencies:\n",
        "                    frequencies[word] = 1\n",
        "                else:\n",
        "                    frequencies[word] += 1\n",
        "\n",
        "                if frequencies[word] == self.freq_threshold:\n",
        "                    self.stoi[word] = idx\n",
        "                    self.itos[idx] = word\n",
        "                    idx += 1\n",
        "\n",
        "    def numericalize(self, text: str) -> List[int]:\n",
        "        tokenized_text = self.tokenizer_eng(text)\n",
        "        return [\n",
        "            self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"]\n",
        "            for token in tokenized_text\n",
        "        ]\n",
        "\n",
        "class FlickrDataset(Dataset):\n",
        "\n",
        "    def __init__(self, root_dir: str, captions_file: str, transform: Any = None, freq_threshold: int = 5):\n",
        "        self.root_dir = root_dir\n",
        "        self.df = pd.read_csv(captions_file)\n",
        "        self.transform = transform\n",
        "\n",
        "        #  image and caption columns\n",
        "        self.imgs = self.df[\"image\"]\n",
        "        self.captions = self.df[\"caption\"]\n",
        "\n",
        "\n",
        "        self.vocab = Vocabulary(freq_threshold)\n",
        "        self.vocab.build_vocabulary(self.captions.tolist())\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        caption = self.captions[index]\n",
        "        img_id = self.imgs[index]\n",
        "        img_path = os.path.join(self.root_dir, img_id)\n",
        "\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        # Numericalize Caption\n",
        "        numericalized_caption = [self.vocab.stoi[\"<SOS>\"]]\n",
        "        numericalized_caption += self.vocab.numericalize(caption)\n",
        "        numericalized_caption += [self.vocab.stoi[\"<EOS>\"]]\n",
        "\n",
        "        return img, torch.tensor(numericalized_caption)\n",
        "\n",
        "class MyCollate:\n",
        "\n",
        "    def __init__(self, pad_idx: int):\n",
        "        self.pad_idx = pad_idx\n",
        "\n",
        "    def __call__(self, batch: List[Tuple[torch.Tensor, torch.Tensor]]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        imgs = [item[0].unsqueeze(0) for item in batch]\n",
        "        imgs = torch.cat(imgs, dim=0)\n",
        "\n",
        "        targets = [item[1] for item in batch]\n",
        "\n",
        "        targets = pad_sequence(targets, batch_first=True, padding_value=self.pad_idx)\n",
        "\n",
        "        return imgs, targets\n",
        "\n",
        "def get_loader(\n",
        "    root_folder: str,\n",
        "    annotation_file: str,\n",
        "    transform: Any,\n",
        "    batch_size: int = 32,\n",
        "    num_workers: int = 8,\n",
        "    shuffle: bool = True,\n",
        "    pin_memory: bool = True,\n",
        ") -> Tuple[DataLoader, FlickrDataset]:\n",
        "\n",
        "    dataset = FlickrDataset(root_folder, annotation_file, transform=transform)\n",
        "    pad_idx = dataset.vocab.stoi[\"<PAD>\"]\n",
        "\n",
        "    loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        shuffle=shuffle,\n",
        "        pin_memory=pin_memory,\n",
        "        collate_fn=MyCollate(pad_idx=pad_idx),\n",
        "    )\n",
        "\n",
        "    return loader, dataset\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "kh5UUwpvm50t"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5CW_blhXoBND"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}